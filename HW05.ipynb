{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8969280",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pandas as pd\n",
    "\n",
    "def is_chinese(string):\n",
    "    for ch in string:\n",
    "        if u'\\u4e00' <= ch <= u'\\u9fff':\n",
    "            return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def init():\n",
    "    lists = []\n",
    "    # reading the json file\n",
    "    with open('./translation2019zh/translation2019zh_train.json','r', encoding='utf-8') as dat_f:\n",
    "        data = []\n",
    "        for i,line in enumerate(dat_f):\n",
    "            data = json.loads(line)\n",
    "\n",
    "            if is_chinese(data['chinese']) == True:\n",
    "                if len(data['chinese'])<6:\n",
    "                    lists.append(data)\n",
    "                if (len(lists)+1)%100 == 0:\n",
    "                    break\n",
    "\n",
    "    df = pd.DataFrame(lists)\n",
    "    df.to_csv('datafile.csv', encoding='utf-8', index=False)\n",
    "    \n",
    "\n",
    "init()\n",
    "df = pd.read_csv('datafile.csv')\n",
    "df['chinese'] = df['chinese'].apply(lambda x: '@' + x + '。')\n",
    "en_data = df.english.values.tolist()\n",
    "ch_data = df.chinese.values.tolist()\n",
    "en_vocab = set(''.join(en_data))\n",
    "id2en = list(en_vocab)\n",
    "en2id = {c:i for i,c in enumerate(id2en)}\n",
    "ch_vocab = set(''.join(ch_data))\n",
    "id2ch = list(ch_vocab)\n",
    "ch2id = {c:i for i,c in enumerate(id2ch)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7fed6f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max encoder length: 75\n",
      "max decoder length: 7\n",
      "index data:\n",
      " [5, 41, 57, 49, 50, 28, 33, 49, 3, 24, 33, 33, 57, 33, 33, 57, 0, 49, 25, 62, 49, 28, 49, 0, 57, 51, 14, 45, 53]\n",
      "one hot data:\n",
      " [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def num_data(en2id,ch2id,en_data):\n",
    "    en_num_data = [[en2id[en] for en in line ] for line in en_data]\n",
    "    ch_num_data = [[ch2id[ch] for ch in line] for line in ch_data]\n",
    "    de_num_data = [[ch2id[ch] for ch in line][1:] for line in ch_data]\n",
    " \n",
    "    max_encoder_seq_length = max([len(txt) for txt in en_num_data])\n",
    "    max_decoder_seq_length = max([len(txt) for txt in ch_num_data])\n",
    "    print('max encoder length:', max_encoder_seq_length)\n",
    "    print('max decoder length:', max_decoder_seq_length)\n",
    "\n",
    "    encoder_input_data = np.zeros((len(en_num_data), max_encoder_seq_length, len(en2id)), dtype='float32')\n",
    "    decoder_input_data = np.zeros((len(ch_num_data), max_decoder_seq_length, len(ch2id)), dtype='float32')\n",
    "    decoder_target_data = np.zeros((len(ch_num_data), max_decoder_seq_length, len(ch2id)), dtype='float32')\n",
    "\n",
    "    for i in range(len(ch_num_data)):\n",
    "        for t, j in enumerate(en_num_data[i]):\n",
    "            encoder_input_data[i, t, j] = 1.\n",
    "        for t, j in enumerate(ch_num_data[i]):\n",
    "            decoder_input_data[i, t, j] = 1.\n",
    "        for t, j in enumerate(de_num_data[i]):\n",
    "            decoder_target_data[i, t, j] = 1.\n",
    "\n",
    "    print('index data:\\n', en_num_data[1])\n",
    "    print('one hot data:\\n', encoder_input_data[1])\n",
    "    return encoder_input_data,decoder_input_data,decoder_target_data\n",
    "\n",
    "nd = num_data(en2id,ch2id,en_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea6133c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_8\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_17 (InputLayer)           [(None, None, 67)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_18 (InputLayer)           [(None, None, 281)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm_14 (LSTM)                  [(None, None, 256),  331776      input_17[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_16 (LSTM)                  [(None, None, 256),  550912      input_18[0][0]                   \n",
      "                                                                 lstm_14[0][1]                    \n",
      "                                                                 lstm_14[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_15 (LSTM)                  [(None, 256), (None, 525312      lstm_14[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_17 (LSTM)                  [(None, None, 256),  525312      lstm_16[0][0]                    \n",
      "                                                                 lstm_15[0][1]                    \n",
      "                                                                 lstm_15[0][2]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, None, 281)    72217       lstm_17[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,005,529\n",
      "Trainable params: 2,005,529\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/250\n",
      "5/5 [==============================] - 5s 137ms/step - loss: 4.3559 - accuracy: 0.1948\n",
      "Epoch 2/250\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 3.8959 - accuracy: 0.2323\n",
      "Epoch 3/250\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 3.3863 - accuracy: 0.2468\n",
      "Epoch 4/250\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 3.2652 - accuracy: 0.2511\n",
      "Epoch 5/250\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 3.1067 - accuracy: 0.2525\n",
      "Epoch 6/250\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 3.0402 - accuracy: 0.2525\n",
      "Epoch 7/250\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 2.9749 - accuracy: 0.2525\n",
      "Epoch 8/250\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 2.9225 - accuracy: 0.2569\n",
      "Epoch 9/250\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 2.8488 - accuracy: 0.2554\n",
      "Epoch 10/250\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 2.7878 - accuracy: 0.2540\n",
      "Epoch 11/250\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 2.7515 - accuracy: 0.2482\n",
      "Epoch 12/250\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 2.6912 - accuracy: 0.2612\n",
      "Epoch 13/250\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 2.6375 - accuracy: 0.2597\n",
      "Epoch 14/250\n",
      "5/5 [==============================] - 1s 143ms/step - loss: 2.5938 - accuracy: 0.2583\n",
      "Epoch 15/250\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 2.5473 - accuracy: 0.2641\n",
      "Epoch 16/250\n",
      "5/5 [==============================] - 1s 142ms/step - loss: 2.5592 - accuracy: 0.2583\n",
      "Epoch 17/250\n",
      "5/5 [==============================] - 1s 160ms/step - loss: 2.4886 - accuracy: 0.2597\n",
      "Epoch 18/250\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 2.4358 - accuracy: 0.2655\n",
      "Epoch 19/250\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 2.3890 - accuracy: 0.2698\n",
      "Epoch 20/250\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 2.3422 - accuracy: 0.2785\n",
      "Epoch 21/250\n",
      "5/5 [==============================] - 1s 147ms/step - loss: 2.2764 - accuracy: 0.2828\n",
      "Epoch 22/250\n",
      "5/5 [==============================] - 1s 150ms/step - loss: 2.2211 - accuracy: 0.2915\n",
      "Epoch 23/250\n",
      "5/5 [==============================] - 1s 145ms/step - loss: 2.1629 - accuracy: 0.2958\n",
      "Epoch 24/250\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 2.1040 - accuracy: 0.3059\n",
      "Epoch 25/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 2.0810 - accuracy: 0.3175\n",
      "Epoch 26/250\n",
      "5/5 [==============================] - 1s 139ms/step - loss: 1.9800 - accuracy: 0.3261\n",
      "Epoch 27/250\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 1.9172 - accuracy: 0.3362\n",
      "Epoch 28/250\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 1.8575 - accuracy: 0.3449\n",
      "Epoch 29/250\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 1.7913 - accuracy: 0.3535\n",
      "Epoch 30/250\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 1.7146 - accuracy: 0.3838\n",
      "Epoch 31/250\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 1.6593 - accuracy: 0.4026\n",
      "Epoch 32/250\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 1.5989 - accuracy: 0.3925\n",
      "Epoch 33/250\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 1.5138 - accuracy: 0.4416\n",
      "Epoch 34/250\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 1.4274 - accuracy: 0.4704\n",
      "Epoch 35/250\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 1.3886 - accuracy: 0.4776\n",
      "Epoch 36/250\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 1.3146 - accuracy: 0.5022\n",
      "Epoch 37/250\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 1.3391 - accuracy: 0.4820\n",
      "Epoch 38/250\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 1.3627 - accuracy: 0.4603\n",
      "Epoch 39/250\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 1.3384 - accuracy: 0.5007\n",
      "Epoch 40/250\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 1.1806 - accuracy: 0.5382\n",
      "Epoch 41/250\n",
      "5/5 [==============================] - 1s 120ms/step - loss: 1.1086 - accuracy: 0.5642\n",
      "Epoch 42/250\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 1.0082 - accuracy: 0.6104\n",
      "Epoch 43/250\n",
      "5/5 [==============================] - 1s 140ms/step - loss: 0.9494 - accuracy: 0.6133\n",
      "Epoch 44/250\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.9010 - accuracy: 0.6263\n",
      "Epoch 45/250\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.8528 - accuracy: 0.6364\n",
      "Epoch 46/250\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.8135 - accuracy: 0.6407\n",
      "Epoch 47/250\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.7853 - accuracy: 0.6436\n",
      "Epoch 48/250\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.7640 - accuracy: 0.6436\n",
      "Epoch 49/250\n",
      "5/5 [==============================] - 1s 133ms/step - loss: 0.7416 - accuracy: 0.6508\n",
      "Epoch 50/250\n",
      "5/5 [==============================] - 1s 121ms/step - loss: 0.7277 - accuracy: 0.6508\n",
      "Epoch 51/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.7172 - accuracy: 0.6508\n",
      "Epoch 52/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.7098 - accuracy: 0.6494\n",
      "Epoch 53/250\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.7073 - accuracy: 0.6494\n",
      "Epoch 54/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.7094 - accuracy: 0.6494\n",
      "Epoch 55/250\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.6972 - accuracy: 0.6551\n",
      "Epoch 56/250\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.7013 - accuracy: 0.6494\n",
      "Epoch 57/250\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.6930 - accuracy: 0.6479\n",
      "Epoch 58/250\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.6836 - accuracy: 0.6522\n",
      "Epoch 59/250\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.6834 - accuracy: 0.6508\n",
      "Epoch 60/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6823 - accuracy: 0.6522\n",
      "Epoch 61/250\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.6840 - accuracy: 0.6508\n",
      "Epoch 62/250\n",
      "5/5 [==============================] - 1s 123ms/step - loss: 0.6785 - accuracy: 0.6508\n",
      "Epoch 63/250\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.6785 - accuracy: 0.6522\n",
      "Epoch 64/250\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.6774 - accuracy: 0.6508\n",
      "Epoch 65/250\n",
      "5/5 [==============================] - 1s 130ms/step - loss: 0.6755 - accuracy: 0.6508\n",
      "Epoch 66/250\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.6780 - accuracy: 0.6479\n",
      "Epoch 67/250\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.6785 - accuracy: 0.6522\n",
      "Epoch 68/250\n",
      "5/5 [==============================] - 1s 137ms/step - loss: 0.6756 - accuracy: 0.6522\n",
      "Epoch 69/250\n",
      "5/5 [==============================] - 1s 136ms/step - loss: 0.6741 - accuracy: 0.6522\n",
      "Epoch 70/250\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.6708 - accuracy: 0.6508\n",
      "Epoch 71/250\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.6814 - accuracy: 0.6494\n",
      "Epoch 72/250\n",
      "5/5 [==============================] - 1s 135ms/step - loss: 0.6804 - accuracy: 0.6494\n",
      "Epoch 73/250\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.6807 - accuracy: 0.6522\n",
      "Epoch 74/250\n",
      "5/5 [==============================] - 1s 132ms/step - loss: 0.7308 - accuracy: 0.6494\n",
      "Epoch 75/250\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.6889 - accuracy: 0.6465\n",
      "Epoch 76/250\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.6749 - accuracy: 0.6508\n",
      "Epoch 77/250\n",
      "5/5 [==============================] - 1s 131ms/step - loss: 0.6760 - accuracy: 0.6508\n",
      "Epoch 78/250\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.6713 - accuracy: 0.6522\n",
      "Epoch 79/250\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.6694 - accuracy: 0.6537\n",
      "Epoch 80/250\n",
      "5/5 [==============================] - 1s 134ms/step - loss: 0.6688 - accuracy: 0.6537\n",
      "Epoch 81/250\n",
      "5/5 [==============================] - 1s 144ms/step - loss: 0.6714 - accuracy: 0.6508\n",
      "Epoch 82/250\n",
      "5/5 [==============================] - 1s 149ms/step - loss: 0.6657 - accuracy: 0.6522\n",
      "Epoch 83/250\n",
      "5/5 [==============================] - 1s 138ms/step - loss: 0.6734 - accuracy: 0.6508\n",
      "Epoch 84/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6834 - accuracy: 0.6508\n",
      "Epoch 85/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.6745 - accuracy: 0.6508\n",
      "Epoch 86/250\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.6788 - accuracy: 0.6508\n",
      "Epoch 87/250\n",
      "5/5 [==============================] - 1s 122ms/step - loss: 0.6759 - accuracy: 0.6522\n",
      "Epoch 88/250\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.6666 - accuracy: 0.6522\n",
      "Epoch 89/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6762 - accuracy: 0.6537\n",
      "Epoch 90/250\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.6765 - accuracy: 0.6508\n",
      "Epoch 91/250\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.6799 - accuracy: 0.6494\n",
      "Epoch 92/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6737 - accuracy: 0.6508\n",
      "Epoch 93/250\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.6697 - accuracy: 0.6551\n",
      "Epoch 94/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6666 - accuracy: 0.6494\n",
      "Epoch 95/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6698 - accuracy: 0.6508\n",
      "Epoch 96/250\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.6674 - accuracy: 0.6537\n",
      "Epoch 97/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6660 - accuracy: 0.6537\n",
      "Epoch 98/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6696 - accuracy: 0.6494\n",
      "Epoch 99/250\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.6644 - accuracy: 0.6522\n",
      "Epoch 100/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6685 - accuracy: 0.6522\n",
      "Epoch 101/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.6616 - accuracy: 0.6522\n",
      "Epoch 102/250\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.6682 - accuracy: 0.6479\n",
      "Epoch 103/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.6671 - accuracy: 0.6508\n",
      "Epoch 104/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.6719 - accuracy: 0.6494\n",
      "Epoch 105/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6679 - accuracy: 0.6508\n",
      "Epoch 106/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.6633 - accuracy: 0.6522\n",
      "Epoch 107/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.6643 - accuracy: 0.6508\n",
      "Epoch 108/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6638 - accuracy: 0.6494\n",
      "Epoch 109/250\n",
      "5/5 [==============================] - 1s 129ms/step - loss: 0.6676 - accuracy: 0.6494\n",
      "Epoch 110/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6636 - accuracy: 0.6551\n",
      "Epoch 111/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.6652 - accuracy: 0.6551\n",
      "Epoch 112/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6617 - accuracy: 0.6508\n",
      "Epoch 113/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.6632 - accuracy: 0.6508\n",
      "Epoch 114/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.6647 - accuracy: 0.6508\n",
      "Epoch 115/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.6630 - accuracy: 0.6508\n",
      "Epoch 116/250\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.6665 - accuracy: 0.6494\n",
      "Epoch 117/250\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.6629 - accuracy: 0.6566\n",
      "Epoch 118/250\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.6692 - accuracy: 0.6522\n",
      "Epoch 119/250\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.6630 - accuracy: 0.6551\n",
      "Epoch 120/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.6628 - accuracy: 0.6508\n",
      "Epoch 121/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6617 - accuracy: 0.6551\n",
      "Epoch 122/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6615 - accuracy: 0.6522\n",
      "Epoch 123/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.6597 - accuracy: 0.6551\n",
      "Epoch 124/250\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.6655 - accuracy: 0.6522\n",
      "Epoch 125/250\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.6705 - accuracy: 0.6494\n",
      "Epoch 126/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.6641 - accuracy: 0.6537\n",
      "Epoch 127/250\n",
      "5/5 [==============================] - 1s 125ms/step - loss: 0.6653 - accuracy: 0.6508\n",
      "Epoch 128/250\n",
      "5/5 [==============================] - 1s 128ms/step - loss: 0.6610 - accuracy: 0.6522\n",
      "Epoch 129/250\n",
      "5/5 [==============================] - 1s 127ms/step - loss: 0.6613 - accuracy: 0.6537\n",
      "Epoch 130/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6646 - accuracy: 0.6537\n",
      "Epoch 131/250\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.6643 - accuracy: 0.6479\n",
      "Epoch 132/250\n",
      "5/5 [==============================] - 1s 126ms/step - loss: 0.6634 - accuracy: 0.6522\n",
      "Epoch 133/250\n",
      "5/5 [==============================] - 1s 124ms/step - loss: 0.6612 - accuracy: 0.6551\n",
      "Epoch 134/250\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.6664 - accuracy: 0.6522\n",
      "Epoch 135/250\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.6618 - accuracy: 0.6522\n",
      "Epoch 136/250\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.6623 - accuracy: 0.6522\n",
      "Epoch 137/250\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.6634 - accuracy: 0.6508\n",
      "Epoch 138/250\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.6629 - accuracy: 0.6508\n",
      "Epoch 139/250\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.6660 - accuracy: 0.6508\n",
      "Epoch 140/250\n",
      "5/5 [==============================] - 1s 118ms/step - loss: 0.6602 - accuracy: 0.6522\n",
      "Epoch 141/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 118ms/step - loss: 0.6695 - accuracy: 0.6508\n",
      "Epoch 142/250\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.6626 - accuracy: 0.6508\n",
      "Epoch 143/250\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.6637 - accuracy: 0.6537\n",
      "Epoch 144/250\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.6619 - accuracy: 0.6465\n",
      "Epoch 145/250\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.6630 - accuracy: 0.6537\n",
      "Epoch 146/250\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.6615 - accuracy: 0.6508\n",
      "Epoch 147/250\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.6604 - accuracy: 0.6522\n",
      "Epoch 148/250\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.6615 - accuracy: 0.6522\n",
      "Epoch 149/250\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.6624 - accuracy: 0.6522\n",
      "Epoch 150/250\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.6635 - accuracy: 0.6522\n",
      "Epoch 151/250\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.6606 - accuracy: 0.6494\n",
      "Epoch 152/250\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.6636 - accuracy: 0.6479\n",
      "Epoch 153/250\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.6624 - accuracy: 0.6494\n",
      "Epoch 154/250\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.6633 - accuracy: 0.6494\n",
      "Epoch 155/250\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.6620 - accuracy: 0.6522\n",
      "Epoch 156/250\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.6696 - accuracy: 0.6522\n",
      "Epoch 157/250\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.6646 - accuracy: 0.6522\n",
      "Epoch 158/250\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.6631 - accuracy: 0.6508\n",
      "Epoch 159/250\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.6612 - accuracy: 0.6522\n",
      "Epoch 160/250\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.6696 - accuracy: 0.6551\n",
      "Epoch 161/250\n",
      "5/5 [==============================] - 1s 119ms/step - loss: 0.6654 - accuracy: 0.6508\n",
      "Epoch 162/250\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.6602 - accuracy: 0.6537\n",
      "Epoch 163/250\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.6622 - accuracy: 0.6522\n",
      "Epoch 164/250\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.6612 - accuracy: 0.6508\n",
      "Epoch 165/250\n",
      "5/5 [==============================] - 1s 116ms/step - loss: 0.6594 - accuracy: 0.6537\n",
      "Epoch 166/250\n",
      "5/5 [==============================] - 1s 114ms/step - loss: 0.6599 - accuracy: 0.6508\n",
      "Epoch 167/250\n",
      "5/5 [==============================] - 1s 117ms/step - loss: 0.6575 - accuracy: 0.6522\n",
      "Epoch 168/250\n",
      "5/5 [==============================] - 1s 115ms/step - loss: 0.6600 - accuracy: 0.6508\n",
      "Epoch 169/250\n",
      "4/5 [=======================>......] - ETA: 0s - loss: 0.6542 - accuracy: 0.6571"
     ]
    }
   ],
   "source": [
    "EN_VOCAB_SIZE = len(en2id)\n",
    "CH_VOCAB_SIZE = len(ch2id)\n",
    "HIDDEN_SIZE = 256\n",
    "LEARNING_RATE = 0.01\n",
    "BATCH_SIZE = 20\n",
    "EPOCHS = 250\n",
    "\n",
    "def train():\n",
    "    encoder_inputs = Input(shape=(None, EN_VOCAB_SIZE))\n",
    "    encoder_h1, encoder_state_h1, encoder_state_c1 = LSTM(HIDDEN_SIZE, return_sequences=True, return_state=True)(encoder_inputs)\n",
    "    encoder_h2, encoder_state_h2, encoder_state_c2 = LSTM(HIDDEN_SIZE, return_state=True)(encoder_h1)\n",
    "    decoder_inputs = Input(shape=(None, CH_VOCAB_SIZE))\n",
    "    lstm1 = LSTM(HIDDEN_SIZE, return_sequences=True, return_state=True)\n",
    "    lstm2 = LSTM(HIDDEN_SIZE, return_sequences=True, return_state=True)\n",
    "    decoder_dense = Dense(CH_VOCAB_SIZE, activation='softmax')\n",
    "\n",
    "    decoder_h1, _, _ = lstm1(decoder_inputs, initial_state=[encoder_state_h1, encoder_state_c1])\n",
    "    decoder_h2, _, _ = lstm2(decoder_h1, initial_state=[encoder_state_h2, encoder_state_c2])\n",
    "    decoder_outputs = decoder_dense(decoder_h2)\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "    opt = Adam(lr=LEARNING_RATE, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    model.fit([nd[0], nd[1]], nd[2],batch_size=BATCH_SIZE,epochs=EPOCHS,validation_split=0.)\n",
    "    model.save('s2s.h5')# Save model\n",
    "    encoder_model = Model(encoder_inputs, [encoder_state_h1, encoder_state_c1, encoder_state_h2, encoder_state_c2])# encoder模型和訓練相同\n",
    "    decoder_state_input_h1 = Input(shape=(HIDDEN_SIZE,))# 預測模型中的decoder的初始化狀態需要傳入新的狀態\n",
    "    decoder_state_input_c1 = Input(shape=(HIDDEN_SIZE,))\n",
    "    decoder_state_input_h2 = Input(shape=(HIDDEN_SIZE,))\n",
    "    decoder_state_input_c2 = Input(shape=(HIDDEN_SIZE,))\n",
    "    decoder_h1, state_h1, state_c1 = lstm1(decoder_inputs, initial_state=[decoder_state_input_h1, decoder_state_input_c1])# 使用傳入的值來初始化當前模型的輸入狀態\n",
    "    decoder_h2, state_h2, state_c2 = lstm2(decoder_h1, initial_state=[decoder_state_input_h2, decoder_state_input_c2])\n",
    "    decoder_outputs = decoder_dense(decoder_h2)\n",
    "    decoder_model = Model([decoder_inputs, decoder_state_input_h1, decoder_state_input_c1, decoder_state_input_h2, decoder_state_input_c2], \n",
    "                        [decoder_outputs, state_h1, state_c1, state_h2, state_c2])\n",
    "    return encoder_model,decoder_model\n",
    "\n",
    "model = train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d494093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def result():    \n",
    "    for k in range(0,99):\n",
    "        test_data = nd[0][k:k+1]\n",
    "        h1, c1, h2, c2 = model[0].predict(test_data)\n",
    "        target_seq = np.zeros((1, 1, CH_VOCAB_SIZE))\n",
    "        target_seq[0, 0, ch2id['@']] = 1\n",
    "        outputs = []\n",
    "        while True:\n",
    "            output_tokens, h1, c1, h2, c2 = model[1].predict([target_seq, h1, c1, h2, c2])\n",
    "            sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "            outputs.append(sampled_token_index)\n",
    "            target_seq = np.zeros((1, 1, CH_VOCAB_SIZE))\n",
    "            target_seq[0, 0, sampled_token_index] = 1\n",
    "            if sampled_token_index == ch2id['。'] or len(outputs) > 10:\n",
    "                break\n",
    "        \n",
    "        print(en_data[k])\n",
    "        print(''.join([id2ch[i] for i in outputs]))\n",
    "\n",
    "result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac955a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35f95f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
